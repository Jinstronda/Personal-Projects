{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT1FH//b99ok8jftnTPkR2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jinstronda/Personal-Projects/blob/main/pytorch_personal_utils_helpers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZoHW5gLpLS6",
        "outputId": "f0fa4e9d-0a6c-4593-9a26-6aba1287b4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pytorch_tools.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile pytorch_tools.py\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\"\"\"\n",
        "First we will install all necessary packages and check if they are not present, if they are not present this Script Will Download Them\"\"\"\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def setup_torch_env(\n",
        "    newpackages = None\n",
        "):\n",
        "    \"\"\"Checks for required libraries, installs missing ones, and imports everything needed for PyTorch work.\n",
        "    Args:\n",
        "    newpackages : New Packages that wanna be imported by the User apart from the Default Pytorch Libraries\n",
        "    \"\"\"\n",
        "    import importlib\n",
        "    packages = {\n",
        "        \"torch\": \"torch\",\n",
        "        \"torchvision\": \"torchvision\",\n",
        "        \"torchinfo\": \"torchinfo\",\n",
        "        \"torchmetrics\": \"torchmetrics\",\n",
        "        \"matplotlib\": \"matplotlib\",\n",
        "        \"numpy\": \"numpy\",\n",
        "        \"pandas\": \"pandas\",\n",
        "        \"requests\": \"requests\",\n",
        "    }\n",
        "    if newpackages and isinstance(newpackages,list):\n",
        "      for module in newpackages:\n",
        "        if module not in packages:\n",
        "          packages[module] = module\n",
        "    for module, package in packages.items():\n",
        "        try:\n",
        "            importlib.import_module(module)\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "    global torch, nn, plt, np, pd, requests, zipfile, Path, DataLoader, datasets, transforms, F1Score, ConfusionMatrix, summary\n",
        "    import torch\n",
        "    from torch import nn\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import requests\n",
        "    import zipfile\n",
        "    from pathlib import Path\n",
        "    from torch.utils.data import DataLoader\n",
        "    from torchvision import datasets, transforms\n",
        "    from torchmetrics import F1Score, ConfusionMatrix\n",
        "    from torchinfo import summary\n",
        "\n",
        "    print(\"âœ… PyTorch environment setup complete!\")\n",
        "setup_torch_env()\n",
        "\n",
        "def create_dataloaders(\n",
        "  train_dir: str,\n",
        "  test_dir: str,\n",
        "  train_transform: transforms.Compose,\n",
        "  test_transform: transforms.Compose,\n",
        "  batch_size: int,\n",
        "  train_target_transform = None,\n",
        "  test_target_transform = None\n",
        "):\n",
        "  \"\"\"Creates Dataloaders for Training and Testing\n",
        "\n",
        "  Args:\n",
        "  train_dir : Training Directory.\n",
        "  test_dir: Testing Directory.\n",
        "  train_transform: Transforms Compose Function to do Data Transformation in Train Data\n",
        "  test_transform: Transforms Compose Function To do Data Transformation in Test Data\n",
        "  batch_size: Size of batches for data Loaders\n",
        "  test_target_transform: Transforms Compose Function to do Data Transformation in Test Target Data\n",
        "  train_target_transform: Transforms Compose Function to do Data Transformation in Train Target Data\n",
        "\n",
        "  Returns\n",
        "  A tuple of a (train_dataloader, test_dataloader, class_names)\n",
        "  class_names is a list of the Target Classes\n",
        "\"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  NUM_WORKERS = os.cpu_count()\n",
        "  train_data = datasets.ImageFolder(root=train_dir,transform=train_transform, target_transform = train_target_transform)\n",
        "  test_data = datasets.ImageFolder(root=test_dir, transform=test_transform, target_transform = test_target_transform)\n",
        "  class_names = train_data.classes\n",
        "  train_dataloader = DataLoader(\n",
        "      dataset=train_data,\n",
        "      num_workers=NUM_WORKERS,\n",
        "      shuffle=True,\n",
        "      batch_size = batch_size,\n",
        "      pin_memory=True\n",
        "  )\n",
        "  test_dataloader = DataLoader(\n",
        "      dataset=test_data,\n",
        "      num_workers=NUM_WORKERS,\n",
        "      shuffle=False,\n",
        "      batch_size = batch_size,\n",
        "      pin_memory = True\n",
        "  )\n",
        "  return (train_dataloader,test_dataloader,class_names)\n",
        "\n",
        "def train_step_classification(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        "    num_classes\n",
        "  ):\n",
        "  \"\"\"Does one Epoch of Training for Classification Tasks\n",
        "\n",
        "  Args:\n",
        "  model: A Pytorch Model\n",
        "  loss_fn: The loss Function\n",
        "  optimizer: THe Optimizer Being Used\n",
        "  train_dataloader: The DataLoader for The Training Data\n",
        "  num_classes: The number of classes for the classification task\n",
        "\n",
        "  Returns:\n",
        "  Tuple: (train_accuracy,train_f1,train_loss)\n",
        "  train_accuracy: The accuracy on the training Data\n",
        "  train_f1: The F1 Score on the training data for that Epoch\n",
        "  train_loss: The Loss of that Epoch.\n",
        "  \"\"\"\n",
        "  from torchmetrics import F1Score, ConfusionMatrix, Accuracy\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if num_classes == 2:\n",
        "    f1_metric = F1Score(task=\"binary\",num_classes=num_classes).to(device)\n",
        "    accuracy_metric = Accuracy(task=\"binary\",num_classes=num_classes).to(device)\n",
        "  else:\n",
        "    f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
        "    accuracy_metric = Accuracy(task=\"multiclass\",num_classes=num_classes).to(device)\n",
        "  total_loss = 0.0\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  for X,y in train_dataloader:\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    total_loss += loss.item()\n",
        "    accuracy_metric.update(y_pred,y)\n",
        "    f1_metric.update(y_pred,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  overall_accuracy = accuracy_metric.compute().item()\n",
        "  overall_f1 = f1_metric.compute().item()\n",
        "  accuracy_metric.reset()\n",
        "  f1_metric.reset()\n",
        "  return (avg_loss,overall_f1,overall_accuracy)\n",
        "\n",
        "def test_step_classification(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    num_classes,\n",
        "    test_dataloader\n",
        "):\n",
        "  \"\"\" Do a Test Step on the Model for Classification Tasks\n",
        "\n",
        "  Args:\n",
        "  model = A pytorch Model\n",
        "  loss_fn = A pytorch Loss Function\n",
        "  num_classes = The number of classes in order to create Accuracy and F1 Score\n",
        "  test_dataloader = The Test Dataloader to perform the Checks.\n",
        "\n",
        "  Returns:\n",
        "  Tuple: (test_accuracy,test_f1,test_loss)\n",
        "  test_accuracy : The Average Accuracy over the Dataloader\n",
        "  test_f1: The Average f1 score over the DataLoader\n",
        "  test_loss : The Average loss over the DataLoader\n",
        "  \"\"\"\n",
        "  import torch\n",
        "  from torchmetrics import F1Score, ConfusionMatrix, Accuracy\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if num_classes == 2:\n",
        "    f1_metric = F1Score(task=\"binary\",num_classes=num_classes).to(device)\n",
        "    accuracy_metric = Accuracy(task=\"binary\",num_classes=num_classes).to(device)\n",
        "  else:\n",
        "    f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
        "    accuracy_metric = Accuracy(task=\"multiclass\",num_classes=num_classes).to(device)\n",
        "  total_loss = 0.0\n",
        "  model.to(device)\n",
        "  model.eval() # Puts the model into eval mode to notify the layers\n",
        "  with torch.inference_mode(): # Apparently this is more effective than no grad\n",
        "    for X,y in test_dataloader:\n",
        "      X,y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "      loss = loss_fn(y_pred,y)\n",
        "      total_loss += loss.item()\n",
        "      accuracy_metric.update(y_pred,y)\n",
        "      f1_metric.update(y_pred,y)\n",
        "  avg_loss = total_loss / len(test_dataloader)\n",
        "  overall_accuracy = accuracy_metric.compute().item()\n",
        "  overall_f1 = f1_metric.compute().item()\n",
        "  accuracy_metric.reset()\n",
        "  f1_metric.reset()\n",
        "  return (avg_loss,overall_f1,overall_accuracy)\n",
        "\n",
        "def train_classification(model,\n",
        "                         train_dataloader,\n",
        "                         test_dataloader,\n",
        "                         optimizer,\n",
        "                         loss_f,\n",
        "                         num_classes,\n",
        "                         epochs):\n",
        "    \"\"\"\n",
        "    Trains and evaluates a classification model over a specified number of epochs.\n",
        "\n",
        "    This function performs training using the train_step_classification function\n",
        "    and evaluates the model by calling the `test_step_classification` function at the end\n",
        "    of each epoch. It collects metrics and returns them in a Dictionary\n",
        "\n",
        "    Args:\n",
        "        model : The PyTorch model to be trained.\n",
        "        train_dataloader : DataLoader for the training dataset.\n",
        "        test_dataloader : DataLoader for the testing dataset.\n",
        "        optimizer ): The optimizer used for training.\n",
        "        loss_f : The loss function used for training.\n",
        "        num_classes (: The number of classes in the classification task.\n",
        "        epochs (: The total number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing training and testing metrics for each epoch.\n",
        "              The keys include:\n",
        "                - train_loss: List of training losses per epoch.\n",
        "                - train_f\": List of training F1 scores per epoch.\n",
        "                - train_acc: List of training accuracies per epoch.\n",
        "                - test_loss: List of testing losses per epoch.\n",
        "                - test_f1: List of testing F1 scores per epoch.\n",
        "                - \"est_acc: List of testing accuracies per epoch.\n",
        "    \"\"\"\n",
        "    from tqdm.auto import tqdm\n",
        "    results = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_f1\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_f1\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_f1, train_acc = train_step_classification(\n",
        "            model=model,\n",
        "            loss_fn=loss_f,\n",
        "            optimizer=optimizer,\n",
        "            train_dataloader=train_dataloader,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "        test_loss, test_f1, test_acc = test_step_classification(\n",
        "            model=model,\n",
        "            loss_fn=loss_f,\n",
        "            num_classes=num_classes,\n",
        "            test_dataloader=test_dataloader\n",
        "        )\n",
        "        if epochs < 20:\n",
        "          print(f\"Epoch: {epoch} | \"\n",
        "                f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "                f\"Test Loss: {test_loss:.4f} | Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "        if epochs > 20 and epochs <50:\n",
        "          if epoch % 5 == 0:\n",
        "            print(f\"Epoch: {epoch} | \"\n",
        "                  f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Test Loss: {test_loss:.4f} | Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "        if epochs > 50:\n",
        "          if epoch%10 == 0:\n",
        "            print(f\"Epoch: {epoch} | \"\n",
        "                  f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Test Loss: {test_loss:.4f} | Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_f1\"].append(train_f1)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_f1\"].append(test_f1)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "    return results\n",
        "\n",
        "def plot_loss_curves(results):\n",
        "  \"\"\" Plots Loss and Accuracy Curve for a Model With a Results Dictionary based on my Training Function\n",
        "\n",
        "  Args:\n",
        "        results (dict): A dictionary containing:\n",
        "            - \"train_loss\" (list): Loss values for the training set over epochs.\n",
        "            - \"test_loss\" (list): Loss values for the test set over epochs.\n",
        "            - \"train_acc\" (list): Accuracy values for the training set over epochs.\n",
        "            - \"test_acc\" (list): Accuracy values for the test set over epochs.\n",
        "  \"\"\"\n",
        "  import matplotlib.pyplot as plt\n",
        "  train_loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "  train_acc = results[\"train_acc\"]\n",
        "  test_acc = results[\"test_acc\"]\n",
        "  train_epochs = range(len(train_loss))\n",
        "  test_epochs = range(len(test_loss))\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(train_epochs, train_loss, label = \"Train Loss\")\n",
        "  plt.plot(test_epochs, test_loss, label = \"Test Loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(train_epochs,train_acc,label = \"Train Accuracy\")\n",
        "  plt.plot(test_epochs, test_acc, label = \"Test Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "e6ONM37cqhQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
